{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "import pathlib\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#Download do dataset\n",
    "'''\n",
    "O comando abaixo vai fazer o download do dataset no diretório atual em que se encontra\n",
    "este notebook\n",
    "'''\n",
    "\n",
    "!wget https://md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com/snkd93bnjr-1.zip"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2021-08-06 01:47:29--  https://md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com/snkd93bnjr-1.zip\n",
      "Resolvendo md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com (md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com)... 52.218.112.168\n",
      "Conectando-se a md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com (md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com)|52.218.112.168|:443... conectado.\n",
      "A requisição HTTP foi enviada, aguardando resposta... 200 OK\n",
      "Tamanho: 278867153 (266M) [application/octet-stream]\n",
      "Salvando em: “snkd93bnjr-1.zip”\n",
      "\n",
      "snkd93bnjr-1.zip    100%[===================>] 265,95M  7,00MB/s    em 49s     \n",
      "\n",
      "2021-08-06 01:48:19 (5,40 MB/s) - “snkd93bnjr-1.zip” salvo [278867153/278867153]\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Criand o diretório onde serão armazenados os dados desejado\n",
    "'''\n",
    "Obs: Está célula de código deve ser executada apenas uma vez. Após esse processo\n",
    "os dados já vão estar no diretório especificado abaixo\n",
    "'''\n",
    "!mkdir '/home/marcos/TCC_2020/dataset'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "!mv snkd93bnjr-1.zip '/home/marcos/TCC_2020/dataset/source_dataset.zip'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nesse ponto houve um processo manual onde o arquivo enviado ao diretório de destino foi descompactado, e então removeu-se os diretórios com imagens que não serão usadas no trabalho, restando apenas 5 diretório cujo nome é referente ao nome as céluas apresentado na imagem.\n",
    "\n",
    "No diretório /home/marcos/TCC_2020/dataset agora se encontram os subdiretórios: basophil, eosinophil, limphocyte, monocyte e neutrophil\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Buscamos as imagens na pasta e criamos uma variavel com os paths.O source_path é\n",
    "# um parâmetro referente ao cainho onde o dataset foi inserido após o download.\n",
    "\n",
    "ROOT_DIR = \"/home/marcos/TCC_2020/dataset/\"\n",
    "PATH_E = ROOT_DIR + \"eosinophil/*.jpg\"\n",
    "PATH_L = ROOT_DIR + \"lymphocyte/*.jpg\"\n",
    "PATH_M = ROOT_DIR + \"monocyte/*.jpg\"\n",
    "PATH_N = ROOT_DIR + \"neutrophil/*.jpg\"\n",
    "PATH_B = ROOT_DIR + \"basophil/*.jpg\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def split_train_val_test_images(file_path):\n",
    "    \n",
    "    file_pattern = str(file_path)\n",
    "    \n",
    "    dataset_paths = [*glob.glob(file_pattern)]\n",
    "    \n",
    "    train_paths, test_paths = train_test_split(dataset_paths,\n",
    "                                               test_size=0.2,\n",
    "                                               random_state=25)   \n",
    "    \n",
    "\n",
    "    print('Dados de Treino:', len(train_paths))\n",
    "    print('Dados de Teste:',len(test_paths))    \n",
    "    \n",
    "    # Usando o método find(), que retorna -1 caso a substring não seja encontrada\n",
    "    sufix = ''\n",
    "    if   file_path.find('eosinophil') != -1: sufix = 'EOSINOPHIL'\n",
    "    elif file_path.find('lymphocyte') != -1: sufix = 'LYMPHOCYTE'\n",
    "    elif file_path.find('monocyte') != -1: sufix = 'MONOCYTE'\n",
    "    elif file_path.find('neutrophil') != -1: sufix = 'NEUTROPHIL'\n",
    "    elif file_path.find('basophil') != -1: sufix = 'BASOPHIL'\n",
    "    \n",
    "    os.makedirs(ROOT_DIR +'train/' + sufix) \n",
    "    os.makedirs(ROOT_DIR +'test/' + sufix)\n",
    "    \n",
    "    \n",
    "    for name in train_paths:            \n",
    "        shutil.copy(name, ROOT_DIR + '/train/' + sufix)\n",
    "    for name in test_paths:               \n",
    "        shutil.copy(name, ROOT_DIR + '/test/' + sufix)    \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "print(\"## eosinofilo ##\")\n",
    "split_train_val_test_images(PATH_E)\n",
    "print(\"## linfocito ##\")\n",
    "split_train_val_test_images(PATH_L)\n",
    "print(\"## monocito ##\")\n",
    "split_train_val_test_images(PATH_M)\n",
    "print(\"## neutrofilo ##\")\n",
    "split_train_val_test_images(PATH_N)\n",
    "print(\"## basofilos ##\")\n",
    "split_train_val_test_images(PATH_B)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "## eosinofilo ##\n",
      "Dados de Treino: 2493\n",
      "Dados de Teste: 624\n",
      "## linfocito ##\n",
      "Dados de Treino: 971\n",
      "Dados de Teste: 243\n",
      "## monocito ##\n",
      "Dados de Treino: 1136\n",
      "Dados de Teste: 284\n",
      "## neutrofilo ##\n",
      "Dados de Treino: 2663\n",
      "Dados de Teste: 666\n",
      "## basofilos ##\n",
      "Dados de Treino: 974\n",
      "Dados de Teste: 244\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Após esse processo, são criados 3 diretórios (train, test, valid) que serão usados no\n",
    "modelo de CNN proposto.\n",
    "Antes, esses três diretórios serão comprimidos no formato .zip e enviado ao drive,\n",
    "possibilidando assim o acesso dos dados aos notebooks que serão executados\n",
    "no googleColaboratory, que apresenta recursos computacionais (GPU) melhores."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('deep_learning': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "interpreter": {
   "hash": "9c4e8c06c2961de79f158c9af0ef34f5fb8ebe735e65364cb23311a0487c021f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}